{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "00_CUDA_env.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/imrickysu/cuda_on_colab/blob/master/00_CUDA_env.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2dvZav6Xipy"
      },
      "source": [
        "# Enable GPU Mode\n",
        "\n",
        "Click menu Runtime -> Change Runtime Type\n",
        "\n",
        "Test GPU with the following commands"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhqm7qfHWiLT",
        "outputId": "c08d78e4-6781-4bf9-a09f-5ee2b56a7d90"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7xPh9xoWm3_",
        "outputId": "991006a3-7afe-4566-a4bc-713ea57578bf"
      },
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "JOCxa885XJsd",
        "outputId": "8071a88a-0bad-4389-cb3d-795683733041"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goZ8uidKY89D",
        "outputId": "fa561b18-11f8-435b-cc58-380193f082b9"
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Mon_Oct_12_20:09:46_PDT_2020\n",
            "Cuda compilation tools, release 11.1, V11.1.105\n",
            "Build cuda_11.1.TC455_06.29190527_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pklPZ2QAeJ8v"
      },
      "source": [
        "# Install NVCC for Jupyter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zd4jQcYeGgq"
      },
      "source": [
        "nvcc4jupyter plugin can let you run CUDA C code in Jupyter Notebook.\n",
        "\n",
        "This is my updated plugin to enable Tesla K80 in CUDA 11."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyQtTz5vajIm",
        "outputId": "36bcafae-2c9d-40ab-a360-d3190e83582d"
      },
      "source": [
        "!pip install git+git://github.com/imrickysu/nvcc4jupyter.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+git://github.com/imrickysu/nvcc4jupyter.git\n",
            "  Cloning git://github.com/imrickysu/nvcc4jupyter.git to /tmp/pip-req-build-q189h4ws\n",
            "  Running command git clone -q git://github.com/imrickysu/nvcc4jupyter.git /tmp/pip-req-build-q189h4ws\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4286 sha256=fa9580ac7cc09ea35c6dbae330e023114b096c6335698951f304fa3d9d0523df\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-k61sfjz7/wheels/77/ca/04/be7399dd9623f64729e513d1c6082358e0c24a309100064304\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yOemQr_HapMA",
        "outputId": "ccadef96-4a06-4aef-8071-323e56f633aa"
      },
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HUO1f_nd2_x"
      },
      "source": [
        "# Execute Single CUDA file with nvcc4jupyter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apo1QHqAekh1"
      },
      "source": [
        "If your CUDA application has only one single source file, you can use `%%cu` magic command to compile this file and execute the compile result."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDD4GspCZVoi",
        "outputId": "5263cee3-0227-4833-c936-25ff05c902f8"
      },
      "source": [
        "%%cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "__global__ void add(int *a, int *b, int *c) {\n",
        "    *c = *a + *b;\n",
        "}\n",
        "\n",
        "int main() {\n",
        "int a, b, c;           // host copies of variables a, b & c\n",
        "int *d_a, *d_b, *d_c;  // device copies of variables a, b & c\n",
        "int size = sizeof(int);\n",
        "\n",
        "// Allocate space for device copies of a, b, c\n",
        "cudaMalloc((void **)&d_a, size);\n",
        "cudaMalloc((void **)&d_b, size);\n",
        "cudaMalloc((void **)&d_c, size);\n",
        "\n",
        "// Setup input values  \n",
        "c = 0;\n",
        "a = 3;\n",
        "b = 5;\n",
        "\n",
        "// Copy inputs to device\n",
        "cudaMemcpy(d_a, &a, size, cudaMemcpyHostToDevice);\n",
        "cudaMemcpy(d_b, &b, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "// Launch add() kernel on GPU\n",
        "add<<<1,1>>>(d_a, d_b, d_c);\n",
        "\n",
        "// Copy result back to host\n",
        "cudaError err = cudaMemcpy(&c, d_c, size, cudaMemcpyDeviceToHost);\n",
        "if(err!=cudaSuccess) {\n",
        "    printf(\"CUDA error copying to Host: %s\\n\", cudaGetErrorString(err));\n",
        "}\n",
        "printf(\"result is %d\\n\",c);\n",
        "\n",
        "// Cleanup\n",
        "cudaFree(d_a);\n",
        "cudaFree(d_b);\n",
        "cudaFree(d_c);\n",
        "return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "result is 8\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9LDsduBe9Jx"
      },
      "source": [
        "If any error happens, e.g. running result is incorrect, you can try running the following host code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAykUjC2b222",
        "outputId": "8277e5e2-f8d0-4f4c-ecf3-454610b07b1c"
      },
      "source": [
        "%%cu\n",
        "\n",
        "#include <iostream>\n",
        "int main()\n",
        "{\n",
        "    std::cout << \"Your host code test works fine.\";\n",
        "    return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your host code test works fine.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miQLHlV0fiSs"
      },
      "source": [
        "# Compiling and Running Multiple Files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbR0VjxMf0Vw"
      },
      "source": [
        "nvcc4jupyter cannot deal with multiple files properly. Write the cu file to storage and call nvcc manually to compile this CUDA program."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ewlsNPQkCCE",
        "outputId": "4bd00670-c023-441b-a23f-bff5023f92e4"
      },
      "source": [
        "%%writefile vectorAdd.cu\n",
        "\n",
        "/**\n",
        " * Copyright 1993-2015 NVIDIA Corporation.  All rights reserved.\n",
        " *\n",
        " * Please refer to the NVIDIA end user license agreement (EULA) associated\n",
        " * with this source code for terms and conditions that govern your use of\n",
        " * this software. Any use, reproduction, disclosure, or distribution of\n",
        " * this software and related documentation outside the terms of the EULA\n",
        " * is strictly prohibited.\n",
        " *\n",
        " */\n",
        "\n",
        "/**\n",
        " * Vector addition: C = A + B.\n",
        " *\n",
        " * This sample is a very basic sample that implements element by element\n",
        " * vector addition. It is the same as the sample illustrating Chapter 2\n",
        " * of the programming guide with some additions like error checking.\n",
        " */\n",
        "\n",
        "#include <stdio.h>\n",
        "\n",
        "// For the CUDA runtime routines (prefixed with \"cuda_\")\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "#include \"helper_cuda.h\"\n",
        "/**\n",
        " * CUDA Kernel Device code\n",
        " *\n",
        " * Computes the vector addition of A and B into C. The 3 vectors have the same\n",
        " * number of elements numElements.\n",
        " */\n",
        "__global__ void\n",
        "vectorAdd(const float *A, const float *B, float *C, int numElements)\n",
        "{\n",
        "    int i = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "\n",
        "    if (i < numElements)\n",
        "    {\n",
        "        C[i] = A[i] + B[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "/**\n",
        " * Host main routine\n",
        " */\n",
        "int\n",
        "main(void)\n",
        "{\n",
        "    // Error code to check return values for CUDA calls\n",
        "    cudaError_t err = cudaSuccess;\n",
        "\n",
        "    // Print the vector length to be used, and compute its size\n",
        "    int numElements = 50000;\n",
        "    size_t size = numElements * sizeof(float);\n",
        "    printf(\"[Vector addition of %d elements]\\n\", numElements);\n",
        "\n",
        "    // Allocate the host input vector A\n",
        "    float *h_A = (float *)malloc(size);\n",
        "\n",
        "    // Allocate the host input vector B\n",
        "    float *h_B = (float *)malloc(size);\n",
        "\n",
        "    // Allocate the host output vector C\n",
        "    float *h_C = (float *)malloc(size);\n",
        "\n",
        "    // Verify that allocations succeeded\n",
        "    if (h_A == NULL || h_B == NULL || h_C == NULL)\n",
        "    {\n",
        "        fprintf(stderr, \"Failed to allocate host vectors!\\n\");\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "\n",
        "    // Initialize the host input vectors\n",
        "    for (int i = 0; i < numElements; ++i)\n",
        "    {\n",
        "        h_A[i] = rand()/(float)RAND_MAX;\n",
        "        h_B[i] = rand()/(float)RAND_MAX;\n",
        "    }\n",
        "\n",
        "    // Allocate the device input vector A\n",
        "    float *d_A = NULL;\n",
        "    err = cudaMalloc((void **)&d_A, size);\n",
        "\n",
        "    if (err != cudaSuccess)\n",
        "    {\n",
        "        fprintf(stderr, \"Failed to allocate device vector A (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "\n",
        "    // Allocate the device input vector B\n",
        "    float *d_B = NULL;\n",
        "    err = cudaMalloc((void **)&d_B, size);\n",
        "\n",
        "    if (err != cudaSuccess)\n",
        "    {\n",
        "        fprintf(stderr, \"Failed to allocate device vector B (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "\n",
        "    // Allocate the device output vector C\n",
        "    float *d_C = NULL;\n",
        "    err = cudaMalloc((void **)&d_C, size);\n",
        "\n",
        "    if (err != cudaSuccess)\n",
        "    {\n",
        "        fprintf(stderr, \"Failed to allocate device vector C (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "\n",
        "    // Copy the host input vectors A and B in host memory to the device input vectors in\n",
        "    // device memory\n",
        "    printf(\"Copy input data from the host memory to the CUDA device\\n\");\n",
        "    err = cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    if (err != cudaSuccess)\n",
        "    {\n",
        "        fprintf(stderr, \"Failed to copy vector A from host to device (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "\n",
        "    err = cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    if (err != cudaSuccess)\n",
        "    {\n",
        "        fprintf(stderr, \"Failed to copy vector B from host to device (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "\n",
        "    // Launch the Vector Add CUDA Kernel\n",
        "    int threadsPerBlock = 256;\n",
        "    int blocksPerGrid =(numElements + threadsPerBlock - 1) / threadsPerBlock;\n",
        "    printf(\"CUDA kernel launch with %d blocks of %d threads\\n\", blocksPerGrid, threadsPerBlock);\n",
        "    vectorAdd<<<blocksPerGrid, threadsPerBlock>>>(d_A, d_B, d_C, numElements);\n",
        "    err = cudaGetLastError();\n",
        "\n",
        "    if (err != cudaSuccess)\n",
        "    {\n",
        "        fprintf(stderr, \"Failed to launch vectorAdd kernel (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "\n",
        "    // Copy the device result vector in device memory to the host result vector\n",
        "    // in host memory.\n",
        "    printf(\"Copy output data from the CUDA device to the host memory\\n\");\n",
        "    err = cudaMemcpy(h_C, d_C, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    if (err != cudaSuccess)\n",
        "    {\n",
        "        fprintf(stderr, \"Failed to copy vector C from device to host (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "\n",
        "    // Verify that the result vector is correct\n",
        "    for (int i = 0; i < numElements; ++i)\n",
        "    {\n",
        "        if (fabs(h_A[i] + h_B[i] - h_C[i]) > 1e-5)\n",
        "        {\n",
        "            fprintf(stderr, \"Result verification failed at element %d!\\n\", i);\n",
        "            exit(EXIT_FAILURE);\n",
        "        }\n",
        "    }\n",
        "\n",
        "    printf(\"Test PASSED\\n\");\n",
        "\n",
        "    // Free device global memory\n",
        "    err = cudaFree(d_A);\n",
        "\n",
        "    if (err != cudaSuccess)\n",
        "    {\n",
        "        fprintf(stderr, \"Failed to free device vector A (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "\n",
        "    err = cudaFree(d_B);\n",
        "\n",
        "    if (err != cudaSuccess)\n",
        "    {\n",
        "        fprintf(stderr, \"Failed to free device vector B (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "\n",
        "    err = cudaFree(d_C);\n",
        "\n",
        "    if (err != cudaSuccess)\n",
        "    {\n",
        "        fprintf(stderr, \"Failed to free device vector C (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "\n",
        "    // Free host memory\n",
        "    free(h_A);\n",
        "    free(h_B);\n",
        "    free(h_C);\n",
        "\n",
        "    printf(\"Done\\n\");\n",
        "    return 0;\n",
        "}\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing vectorAdd.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DueNWCYsg0iT",
        "outputId": "961c0504-dffe-4e05-93ea-bbaa747f21ef"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/NVIDIA/cuda-samples/master/Common/helper_cuda.h\n",
        "!wget https://raw.githubusercontent.com/NVIDIA/cuda-samples/master/Common/helper_string.h"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-09 14:54:24--  https://raw.githubusercontent.com/NVIDIA/cuda-samples/master/Common/helper_cuda.h\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 27706 (27K) [text/plain]\n",
            "Saving to: ‘helper_cuda.h.1’\n",
            "\n",
            "\rhelper_cuda.h.1       0%[                    ]       0  --.-KB/s               \rhelper_cuda.h.1     100%[===================>]  27.06K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2021-10-09 14:54:24 (12.6 MB/s) - ‘helper_cuda.h.1’ saved [27706/27706]\n",
            "\n",
            "--2021-10-09 14:54:24--  https://raw.githubusercontent.com/NVIDIA/cuda-samples/master/Common/helper_string.h\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11242 (11K) [text/plain]\n",
            "Saving to: ‘helper_string.h’\n",
            "\n",
            "helper_string.h     100%[===================>]  10.98K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-10-09 14:54:25 (80.6 MB/s) - ‘helper_string.h’ saved [11242/11242]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j57C_O92gAsB"
      },
      "source": [
        "If your allocated GPU is K80, you'll get an error using nvcc of CUDA 11 directly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qn_nWUysnu_T",
        "outputId": "455c4ea7-c4ab-4957-9be8-e9eb484fe064"
      },
      "source": [
        "!nvcc vectorAdd.cu -o vectorAdd && ./vectorAdd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In file included from \u001b[01m\u001b[KvectorAdd.cu:26:0\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[Khelper_cuda.h:41:10:\u001b[m\u001b[K \u001b[01;31m\u001b[Kfatal error: \u001b[m\u001b[Khelper_string.h: No such file or directory\n",
            " #include \u001b[01;31m\u001b[K<helper_string.h>\u001b[m\u001b[K\n",
            "          \u001b[01;31m\u001b[K^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "compilation terminated.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-t9p0tfgKNp"
      },
      "source": [
        "You need to add `-arch=sm_37` to specify K80 architecture because this sm is below the default supported arch of CUDA 11.\n",
        "The output warning can be ignored in CUDA 11. It means CUDA may not support K80 in the future."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkwtzEISku_L",
        "outputId": "ae4bf314-b9b8-44c9-81cb-478511b045c3"
      },
      "source": [
        "!nvcc vectorAdd.cu -arch=sm_37 -o vectorAdd && ./vectorAdd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "[Vector addition of 50000 elements]\n",
            "Copy input data from the host memory to the CUDA device\n",
            "CUDA kernel launch with 196 blocks of 256 threads\n",
            "Copy output data from the CUDA device to the host memory\n",
            "Test PASSED\n",
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HR9dVnagkJX"
      },
      "source": [
        "Execute the compilation output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJMH3AZodsTH"
      },
      "source": [
        "# Write and Compile C++ Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39_RCy7TdUcA",
        "outputId": "bcfcdf07-8598-4192-e835-45b84e3a5733"
      },
      "source": [
        "%%writefile welcome.cpp\n",
        "\n",
        "#include <iostream>\n",
        "int main()\n",
        "{\n",
        "    std::cout << \"Hello World\\n\";\n",
        "    return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing welcome.cpp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5CGTUxSdhhm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6adddc43-3547-4e1d-f640-06c46583c554"
      },
      "source": [
        "!g++ welcome.cpp -o welcome && ./welcome"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello World\n"
          ]
        }
      ]
    }
  ]
}